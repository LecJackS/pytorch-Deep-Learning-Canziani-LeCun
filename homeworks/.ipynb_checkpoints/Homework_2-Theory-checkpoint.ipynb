{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-GA 1008: Deep Learning, Spring 2020\n",
    "\n",
    "# Homework Assignment 2\n",
    "\n",
    ">*The search for truth is more precious than its possession.*\n",
    ">\n",
    ">Albert Einstein (1879 - 1955)\n",
    "\n",
    "## 1. Fundamentals\n",
    "\n",
    "### 1.1. Convolution\n",
    "\n",
    "**Table 1** depicts two matrices:\n",
    "\n",
    "> **Table 1**: Image Matrix (5 × 5) and a convolution kernel (3 × 3).\n",
    "> \n",
    "> $$A=\\left[\\begin{matrix} 4 && 5 && 2 && 2 && 1\\\\\n",
    "3 && 3 && 2 && 2 && 4\\\\\n",
    "4 && 3 && 4 && 1 && 1\\\\\n",
    "5 && 1 && 4 && 1 && 2\\\\\n",
    "5 && 1 && 3 && 1 && 4\\\\\n",
    "\\end{matrix}\\right] \\ \\ \n",
    "B=\\left[\\begin{matrix} 4 && 3 && 3\\\\\n",
    "5 && 5 && 5\\\\\n",
    "2 && 4 && 3\\\\\n",
    "\\end{matrix}\\right]$$\n",
    ">\n",
    ">\n",
    ">* The one on the left represents an 5 × 5 single-channel image A.\n",
    ">\n",
    ">\n",
    ">* The one on the right represents a 3 × 3 convolution kernel B.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(a)** What is the **dimensionality of the output** if we forward propagate the image over the given convolution kernel with **no padding** and stride of 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Answer:**\n",
    "\n",
    "|Output dim|\n",
    "|--|\n",
    "|$$3 \\times 3$$|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(b)** Give a general formula of the **output width** $O$ in terms of the:\n",
    "  * input width $I$,\n",
    "  \n",
    "  * kernel width $K$,\n",
    "  \n",
    "  * stride $S$,\n",
    "  \n",
    "  * and padding $P$ (both in the beginning and in the end).\n",
    "  \n",
    "  Note that the same formula holds for the height.\n",
    "  \n",
    "  Make sure that your answer in part **(a)** is consistent with your formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Answer:**\n",
    "\n",
    "|Output width $O$|\n",
    "|--|\n",
    "|$$I - S(K-1)+ 2P$$|\n",
    "\n",
    "Values from part **(a)**:\n",
    "\n",
    "> $I=5$\n",
    ">\n",
    "> $K=3$\n",
    ">\n",
    "> $S=1$\n",
    ">\n",
    "> $P=0$\n",
    "\n",
    "Replacing on the formula:\n",
    "$$5 - 1(3-1)+ 2(0) = 3$$\n",
    "\n",
    "Which is the same answer given in **(a)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(c)** Compute the **output** $\\mathbf C$ of forward propagating the image over the given convolution kernel.\n",
    "  \n",
    "  Assume that the bias term of the convolution is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image:\n",
    "$$A=\\left[\\begin{matrix} 4 && 5 && 2 && 2 && 1\\\\\n",
    "3 && 3 && 2 && 2 && 4\\\\\n",
    "4 && 3 && 4 && 1 && 1\\\\\n",
    "5 && 1 && 4 && 1 && 2\\\\\n",
    "5 && 1 && 3 && 1 && 4\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "Kernel:\n",
    "$$B=\\left[\\begin{matrix} 4 && 3 && 3\\\\\n",
    "5 && 5 && 5\\\\\n",
    "2 && 4 && 3\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "The convolution operation consists on computing the dot product of each $3 \\times 3$ *sub-matrix* of $A$ times the kernel $B$ (assuming no padding and stride = 1, as specified on **(a)**)\n",
    "\n",
    "$$Conv_B(A) = \\mathbf C$$\n",
    "\n",
    "Where $Conv_B(A)$ corresponds to the convolution operation on matrix $A$, with Toeplitz matrix of kernel $B$\n",
    "\n",
    "And each $3 \\times 3$ *sub matrix* $A_{sub_{3\\times3}(ij)}$ is given by:\n",
    "$$A_{sub_{3\\times3}(ij)} =\\left[\\begin{matrix} A_{i,j} && A_{i,j+1} && A_{i,j+2}\\\\\n",
    "A_{i+1,j} && A_{i+1,j+1} && A_{i+1,j+2}\\\\\n",
    "A_{i+2,j} && A_{i+2,j+1} && A_{i+2,j+2}\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "with $i,j \\in [1,3]$\n",
    "\n",
    "Using (simplified) Python notation (right bound included):\n",
    "\n",
    "$$A_{sub_{3\\times3}(ij)} = A_{[i:i+2][j:j+2]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Conv_B(A) =\\left[\\begin{matrix} \\left< A_{[1:3][1:3]}, B \\right> && \\left<A_{[1:3][2:4]}, B \\right> && \\left<A_{[1:3][3:5]}, B \\right>\\\\\n",
    "\\left<A_{[2:3][1:3]}, B \\right> && \\left<A_{[2:4][2:4]}, B \\right> && \\left<A_{[2:4][3:5]}, B \\right>\\\\\n",
    "\\left<A_{[3:5][1:3]}, B \\right> && \\left<A_{[3:5][2:4]}, B \\right> && \\left<A_{[3:5][3:5]}, B \\right>\\\\\n",
    "\\end{matrix}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be more clear (at the risk of losing my mind writing it):\n",
    "\n",
    "$$A=\\left[\\begin{matrix} 4 && 5 && 2 && 2 && 1\\\\\n",
    "3 && 3 && 2 && 2 && 4\\\\\n",
    "4 && 3 && 4 && 1 && 1\\\\\n",
    "5 && 1 && 4 && 1 && 2\\\\\n",
    "5 && 1 && 3 && 1 && 4\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "$$Conv_B(A) = \\left[\\begin{matrix} \\left<\\left[\\begin{matrix} 4 && 5 && 2\\\\\n",
    "3 && 3 && 2\\\\\n",
    "4 && 3 && 4\\\\\n",
    "\\end{matrix}\\right], B\\right> && \\left<\\left[\\begin{matrix} 5 && 2 && 2\\\\\n",
    "3 && 2 && 2\\\\\n",
    "3 && 4 && 1\\\\\n",
    "\\end{matrix}\\right], B\\right> && \\left<\\left[\\begin{matrix} 2 && 2 && 1\\\\\n",
    "2 && 2 && 4\\\\\n",
    "4 && 1 && 1\\\\\n",
    "\\end{matrix}\\right], B\\right>\\\\\n",
    "\\left<\\left[\\begin{matrix} 3 && 3 && 2\\\\\n",
    "4 && 3 && 4\\\\\n",
    "5 && 1 && 4\\\\\n",
    "\\end{matrix}\\right], B\\right> && \\left<\\left[\\begin{matrix} 3 && 2 && 2\\\\\n",
    "3 && 4 && 1\\\\\n",
    "1 && 4 && 1\\\\\n",
    "\\end{matrix}\\right], B\\right> && \\left<\\left[\\begin{matrix} 2 && 2 && 4\\\\\n",
    "4 && 1 && 1\\\\\n",
    "4 && 1 && 2\\\\\n",
    "\\end{matrix}\\right], B\\right>\\\\\n",
    "\\left<\\left[\\begin{matrix} 4 && 3 && 4\\\\\n",
    "5 && 1 && 4\\\\\n",
    "5 && 1 && 3\\\\\n",
    "\\end{matrix}\\right], B\\right> && \\left<\\left[\\begin{matrix} 3 && 4 && 1\\\\\n",
    "1 && 4 && 1\\\\\n",
    "1 && 3 && 1\\\\\n",
    "\\end{matrix}\\right], B\\right> && \\left<\\left[\\begin{matrix} 4 && 1 && 1\\\\\n",
    "4 && 1 && 2\\\\\n",
    "3 && 1 && 4\\\\\n",
    "\\end{matrix}\\right], B\\right> \\\\\n",
    "\\end{matrix}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not going to compute these 9 inner products by hand, but I could use something calling \"programming\" to help me out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      "[[4. 5. 2. 2. 1.]\n",
      " [3. 3. 2. 2. 4.]\n",
      " [4. 3. 4. 1. 1.]\n",
      " [5. 1. 4. 1. 2.]\n",
      " [5. 1. 3. 1. 4.]]\n",
      "B = \n",
      "[[4. 3. 3.]\n",
      " [5. 5. 5.]\n",
      " [2. 4. 3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.asarray([[4., 5., 2., 2., 1.],\n",
    "                [3., 3., 2., 2., 4.],\n",
    "                [4., 3., 4., 1., 1.],\n",
    "                [5., 1., 4., 1., 2.],\n",
    "                [5., 1., 3., 1., 4.]])\n",
    "\n",
    "B = np.asarray([[4., 3., 3.],\n",
    "                [5., 5., 5.],\n",
    "                [2., 4., 3.]])\n",
    "\n",
    "print(\"A = \\n{}\".format(A))\n",
    "print(\"B = \\n{}\".format(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerProd(X, Y):\n",
    "    \"\"\"Returns inner product of two matrices\"\"\"\n",
    "    if X.shape != Y.shape:\n",
    "        print(\"Error! different shape!\")\n",
    "        return\n",
    "    res = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            res += X[i,j]*Y[i,j]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n",
      "[[109.  92.  72.]\n",
      " [108.  85.  74.]\n",
      " [110.  74.  79.]]\n"
     ]
    }
   ],
   "source": [
    "C = np.zeros((3,3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # Get each 3x3 sub-matrix of A\n",
    "        A_sub = A[i:i+3, j:j+3]\n",
    "        #print(\"A_sub({},{}) = \\n{}\".format(i+1,j+1, A_sub))\n",
    "        C[i, j] = innerProd(A_sub, B)\n",
    "print(\"C = \\n{}\".format(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Output $\\mathbf C = $|\n",
    "|--|\n",
    "|$$\\left[\\begin{matrix} 109 && 92 && 72\\\\\n",
    "108 && 85 && 74\\\\\n",
    "110 && 74 && 79\\\\\n",
    "\\end{matrix}\\right]$$|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the result using the PyTorch library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "conv = torch.nn.functional.conv2d\n",
    "#conv?\n",
    "#conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert arrays to tensors\n",
    "tA = torch.from_numpy(A)\n",
    "tA = tA.view(1, 1, 5, 5)\n",
    "tB = torch.from_numpy(B)\n",
    "tB = tB.view(1, 1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n",
      "[[[[109.  92.  72.]\n",
      "   [108.  85.  74.]\n",
      "   [110.  74.  79.]]]]\n"
     ]
    }
   ],
   "source": [
    "tC = conv(tA, tB)\n",
    "print(\"C = \\n{}\".format(tC.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the same result as before :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(d)** Suppose the gradient backpropagated from the layers above this layer is a $3 \\times 3$ matrix of all 1s.\n",
    "\n",
    "  Write the value of the gradient with respect to the input image backpropagated out of this layer.\n",
    "  \n",
    "  That is, you are given that  $$\\frac{\\partial E}{\\partial C_{ij}} = 1$$ for some scalar error $E$ and $i,j \\in \\{1,2,3\\}$\n",
    "  \n",
    "  You need to compute $$\\frac{\\partial E}{\\partial A_{ij}}$$ for $i,j \\in \\{1, \\dots ,5\\}$\n",
    "  \n",
    "  The chain rule should help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial A_{ij}} = \\frac{\\partial E}{\\partial C_{kq}} \\frac{\\partial C_{kq}}{\\partial A_{ij}}$$\n",
    "\n",
    "with\n",
    "\n",
    ">$k,q \\in \\{1,2,3\\}$\n",
    ">\n",
    ">$i,j \\in \\{1, \\dots ,5\\}$\n",
    "\n",
    "The partial derivative calculations of $C$ w.r.t. each input value $A_{ij}$ are gonna vary depending on where on the matrix is the $A_{ij}$, because the filter is **not** gonna pass the same amount of times over each $A_{ij}$:\n",
    "\n",
    "1. Only one time:\n",
    "\n",
    "   $$A=\\left[\\begin{matrix} A_{11} && - && - && - && A_{15}\\\\\n",
    "- && - && - && - && -\\\\\n",
    "- && - && - && - && -\\\\\n",
    "- && - && - && - && -\\\\\n",
    "A_{51} && - && - && - && A_{55}\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "   $$A=\\left[\\begin{matrix} A_{11} && A_{12} && A_{13} && A_{14} && A_{15}\\\\\n",
    "A_{21} && - && - && - && A_{25}\\\\\n",
    "A_{31} && - && - && - && A_{35}\\\\\n",
    "A_{41} && - && - && - && A_{45}\\\\\n",
    "A_{51} && A_{52} && A_{53} && A_{54} && A_{55}\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "2. On the second border:\n",
    "\n",
    "    $$A=\\left[\\begin{matrix} - && - && - && - && -\\\\\n",
    "- && A_{22} && A_{23} && A_{24} && -\\\\\n",
    "- && A_{32} && - && A_{34} && -\\\\\n",
    "- && A_{42} && A_{43} && A_{44} && -\\\\\n",
    "- && - && - && - && -\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "3. In the middle: \n",
    "\n",
    "    $$A=\\left[\\begin{matrix} - && - && - && - && -\\\\\n",
    "- && - && - && - && -\\\\\n",
    "- && - && A_{33} && - && -\\\\\n",
    "- && - && - && - && -\\\\\n",
    "- && - && - && - && -\\\\\n",
    "\\end{matrix}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hw2-convolution-partial-derivative.jpg](./img/hw2-convolution-partial-derivative.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Pooling\n",
    "\n",
    "Pooling is a technique for sub-sampling and comes in different flavors, for example max-pooling, average pooling, LP-pooling.\n",
    "\n",
    "* **(a)** List the [torch.nn modules](https://pytorch.org/docs/stable/nn.html) for the 2D versions of these pooling techniques and read what they do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**MaxPool2d** (kernel_size, stride=None, padding=0\n",
    ">\n",
    ">https://pytorch.org/docs/stable/nn.html#maxpool2d\n",
    ">\n",
    "> Applies Max within *kernel_size*, moving by *stride*\n",
    "\n",
    ">**AvgPool2d**\n",
    ">\n",
    "> As MaxPool2d, but average\n",
    "\n",
    ">**FractionalMaxPool2d**\n",
    ">\n",
    "> as MaxPool2d, but with non stochastic step\n",
    "\n",
    ">**LPPool2d**\n",
    ">\n",
    ">Applies a 2D power-average pooling over an input signal composed of several input planes.\n",
    ">\n",
    "> $$\\left( \\sum_{x \\in X} x^p \\right)^\\frac 1 p$$\n",
    ">\n",
    "> At $p = \\infty$ , one gets **Max Pooling**\n",
    ">\n",
    "> At $p = 1$, one gets **Sum Pooling** (which is proportional to average pooling)\n",
    "\n",
    "> **AdaptiveMaxPool2d**\n",
    ">\n",
    "> The output is of size $H \\times W$, for any input size.\n",
    ">\n",
    "> The number of output features is equal to the number of input planes.\n",
    "\n",
    "> **AdaptiveAvgPool2d**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(b)** Denote the k-th input feature maps to a pooling module as X k ∈ R H in ×W in here\n",
    "H in and W in represent the input height and width, respectively.\n",
    "  Let Y k ∈ R H out ×W out denote the k-th output feature map of the module where H out and W out represent the\n",
    "k\n",
    "output height and width, respectively. Let S i,j\n",
    "be a list of the indexes of elements in the\n",
    "k\n",
    "k\n",
    "sub-region of X used for generating Y i,j , the (i, j)-th entry of Y k . Using this notation,\n",
    "give formulas for Y i,j k from three pooling modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(c)** Write out the result of applying a max-pooling module with kernel size of 2 and stride of 1 to C from Part 1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(d)** Show how max-pooling and average pooling can be expressed in terms of LP-pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
